{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nd2reader import ND2Reader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as Patches\n",
    "import numpy as np\n",
    "from skimage.filters import gaussian, threshold_yen\n",
    "from skimage import measure\n",
    "from skimage.util import crop\n",
    "from scipy.ndimage import find_objects, measurements\n",
    "import multiprocessing as mp\n",
    "import gzip\n",
    "import re\n",
    "from numba import jit\n",
    "import time\n",
    "import cv2\n",
    "import cython\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "min_area = 100\n",
    "PATCH_SIZE = 256\n",
    "gimg = None\n",
    "KEEP_Z = 3\n",
    "NUM_CPU = int(mp.cpu_count()/2)-1\n",
    "\n",
    "def main():\n",
    "    image_stack = ImageStack('data/Hackathon/190625_20X_25K_0001.nd2')\n",
    "    #return\n",
    "    all_files = []\n",
    "    for filename in os.listdir(\"data/Hackathon\"): # original nd2 filenames\n",
    "        if re.match(\".*20X.*nd2\", filename):\n",
    "            print(filename)\n",
    "            #all_files.append(filename[:-4])\n",
    "            try:\n",
    "                all_files.append(\"data/Hackathon/\"+filename)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    with mp.Pool(len(all_files)) as p:\n",
    "        p.map(ImageStack, [f for f in all_files])\n",
    "\n",
    "def show_image(img):\n",
    "    \"\"\" Display an image (Y,X)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(img)\n",
    "\n",
    "def illum_filter(img,gauss_sigma=150):\n",
    "    \"\"\" Filter to remove lens abberation.\n",
    "    :param sigma: modifier for blur effect\n",
    "    \"\"\"\n",
    "    if img is None:\n",
    "        return None\n",
    "    fltr = gaussian(img,gauss_sigma)\n",
    "    #show_image(fltr) #debug image\n",
    "    img = img-fltr\n",
    "    img[img<0] = 0\n",
    "    return img.astype(dtype=np.uint32,copy=False)\n",
    "\n",
    "def get_threshold(img, ratio=10):\n",
    "    \"\"\" Threshold for a single image frame. #FAST\n",
    "    Ignores this image if the threshold is below a ratio.\n",
    "    \"\"\"\n",
    "    thr = threshold_yen(img)\n",
    "    background = img[img<thr]\n",
    "    #if thr < ratio*np.mean(background):\n",
    "    #    print(\"thr:{0:.5f}, ratio*mean:{1:.5f}\".format(thr,ratio*img.mean()))\n",
    "    #    return 0\n",
    "    return thr\n",
    "        \n",
    "def is_valid_patch(img, c, patch_size):\n",
    "    \"\"\"\n",
    "    :param: centroid to examine.\n",
    "    \"\"\"\n",
    "    psize = patch_size\n",
    "    height, width = img.shape # YX format\n",
    "    hsize = psize *0.5\n",
    "    return not ((c[1]+hsize > width) or (c[1]-hsize < 0) \n",
    "                or (c[0]+hsize > height) or (c[0]-hsize < 0))\n",
    "\n",
    "#FAST\n",
    "def get_centroids(input_tuple):\n",
    "    \"\"\" Identifies regions and returns midpoints.\n",
    "    \"\"\"\n",
    "    img, patch_size = input_tuple\n",
    "    labels = measure.label(img, background=0, connectivity=1)\n",
    "    centroids = []\n",
    "    show_image(img)\n",
    "    for offset in find_objects(labels):\n",
    "        region = img[offset]\n",
    "        area = (region>0).sum()\n",
    "        if area >= min_area:\n",
    "            offsets = [(sl.start) for sl in offset]\n",
    "            centroid = measurements.center_of_mass(region)\n",
    "            centroid = [int(centroid[0])+offsets[0],int(centroid[1])+offsets[1]]\n",
    "            if is_valid_patch(img, centroid, patch_size):\n",
    "                centroids.append(centroid)\n",
    "                #show_image(region)\n",
    "    return np.asarray(centroids)\n",
    "\n",
    "def debug_show_patches(img, centroids, patch_size):\n",
    "    \"\"\" Draw patch locations on image (single frame).\n",
    "    \"\"\"\n",
    "    hsize = int(patch_size *0.5)\n",
    "    fig,ax = plt.subplots(1,figsize=(10,10))\n",
    "    ax.imshow(img)\n",
    "    for y, x in centroids:\n",
    "        rect = Patches.Rectangle((x -hsize,y - hsize),patch_size,patch_size,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def patchify(input_tuple):\n",
    "    \"\"\" Get image patches at centroid locations.\n",
    "    :param input_tuple: img, centroids\n",
    "    \"\"\"\n",
    "    #start = time.time()\n",
    "    img, centroids, patch_size = input_tuple\n",
    "    hsize = int(patch_size *0.5)\n",
    "    patches = []\n",
    "    for y, x in centroids:\n",
    "        cropped = img[y - hsize:y+hsize, x -hsize:x+hsize]\n",
    "        patches.append(cropped)\n",
    "    #debug_show_patches(img, centroids, patch_size)\n",
    "    #end = time.time(); print(\"patchify: \", end-start, \"seconds\")\n",
    "    return np.asarray(patches)#np.asarray(patches)\n",
    "    \n",
    "def label_patches(patches):\n",
    "    print(patches.shape)\n",
    "    #for v in range(patches.shape[0]):\n",
    "    #    for p in range(patches.shape[3]):\n",
    "    #        label_patch(patches[v][:][:][p])\n",
    "    \n",
    "def label_patch(patch):\n",
    "    print(patch.shape)\n",
    "    \n",
    "class ImageStack:\n",
    "    def __init__(self, img_path):\n",
    "        self.images = {}\n",
    "        self.np_data = None\n",
    "        self.patches = None\n",
    "        self.path = img_path\n",
    "        self.patch_size = PATCH_SIZE\n",
    "        self.n_channels = 4\n",
    "        self.max_z = 7\n",
    "        self.max_v = 0\n",
    "        self.frames = []\n",
    "        ## Read Images in nd2\n",
    "        self.read_nd2(img_path)\n",
    "        \n",
    "    def read_nd2(self, path):\n",
    "        global gimg, NUM_CPU\n",
    "\n",
    "        with ND2Reader(path) as images:\n",
    "            print(\"Starting \" + path)        \n",
    "            self.images = images\n",
    "            #self.images = np.array(images)\n",
    "            #print(self.images.shape)\n",
    "\n",
    "            # Obtain metadata & construct struct container:\n",
    "            self.width = images.metadata['width']\n",
    "            self.height = images.metadata['height']\n",
    "            self.z_levels = images.metadata['z_levels']\n",
    "            self.channels = images.metadata['channels']\n",
    "            self.max_v = images.metadata['fields_of_view'].stop\n",
    "            \n",
    "            if re.match(\".*40X.*\", path):\n",
    "                print(\"40X!\")\n",
    "                self.patch_size = 384\n",
    "\n",
    "            #self.max_v = 2\n",
    "                \n",
    "            print(\"getting centroids...\")\n",
    "            z = 0 # arbitrary index for selecting the z-stack\n",
    "            self.centroids = []\n",
    "            \n",
    "            # Single threaded\n",
    "            for v in range(self.max_v):\n",
    "                self.centroids.append(get_centroids((self.get_merged_nuclei(v), self.patch_size)))\n",
    "                \n",
    "            print(\"patchify...\")\n",
    "            self.patches = []\n",
    "            \n",
    "            for _v in range(self.max_v):\n",
    "                for _z in range(2,5): #self.max_z\n",
    "                    for _c in range(self.n_channels):\n",
    "                        self.patches.append(patchify((self.get_frame_vcz(_v,_c,_z), self.centroids[_v], self.patch_size)))\n",
    "            \"\"\"\n",
    "            for _v in range(self.max_v):\n",
    "                for _c in range(self.n_channels):\n",
    "                    self.patches.append(patchify((self.get_frame_vcz(_v,_c,KEEP_Z), self.centroids[_v], self.patch_size)))\n",
    "            \"\"\"\n",
    "\n",
    "            print(\"finished patchify\")\n",
    "\n",
    "            self.patches = np.asarray(self.patches)\n",
    "            self.patches = np.asarray(np.split(self.patches, 3*self.max_v)) #unc for -z#self.max_z\n",
    "            self.patches = np.asarray(np.split(self.patches, self.max_v))\n",
    "            \n",
    "            gimg = self.patches\n",
    "            \n",
    "            print(\"generating labels...\")\n",
    "            label_patches(self.patches)\n",
    "\n",
    "            #return\n",
    "            \n",
    "            print(\"saving data...\")\n",
    "            file = 'temp_raw/raw_'+re.search(\"\\d*_\\d*X_\\d*._\\d*\", path).group(0)+'.npy'\n",
    "            np.save(file, self.patches, True)\n",
    "            print('saved raw_'+re.search(\"\\d*_\\d*X_\\d*._\\d*\", path).group(0)+'.npy.gz')\n",
    "            \n",
    "    def get_merged_nuclei(self, v):\n",
    "        \"\"\" Assumes at least 3 channels in total.\n",
    "        \"\"\"\n",
    "        #start = time.time();\n",
    "\n",
    "        img = self.get_threshold_vcz(v,1,0)\n",
    "        for z in range(2):#self.max_z):#self.max_z\n",
    "            if z > 0:\n",
    "                img = self.get_threshold_vcz(v,1,z) | img\n",
    "            for _c in range(2,self.n_channels):\n",
    "                img = self.get_threshold_vcz(v,_c,z) | img\n",
    "    \n",
    "        #show_image(img)\n",
    "        #end = time.time(); print(\"get_merged_nuclei: \", end-start, \"seconds\")\n",
    "        return img\n",
    "    \n",
    "    #@jit(nopython = True, parallel = True)\n",
    "    def get_threshold_vcz(self, v, c, z):\n",
    "        \"\"\" Threshold for a channel & z.\n",
    "        :param v: the image index from nd2.\n",
    "        :return: the thresholded image.\n",
    "        \"\"\"\n",
    "        img = self.get_frame_vcz(v,c,z)\n",
    "        thr = get_threshold(img)\n",
    "        return img > thr\n",
    "    \n",
    "    def get_frame_vcz(self, v, c, z):\n",
    "        #return self.images[c + self.n_channels * (z + self.max_z * v)]\n",
    "        return self.images.get_frame_vczyx(v,c,0,z,0,0)\n",
    "        #return img#illum_filter(img) # Fix lens abberation\n",
    "    \n",
    "    def get_c_stack(self, v, z):\n",
    "        stack = np.zeros(shape=(len(self.channels), self.width, self.height), dtype=int)\n",
    "        for c in range(len(self.channels)):\n",
    "            stack[c] = self.get_frame_vcz(v,c,z)\n",
    "        return stack\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "#path = \"patches/raw_20X_50K/data_190627_20X_50K_0001.npy\"\n",
    "NUM_CPU = mp.cpu_count()-1\n",
    "\n",
    "def main():\n",
    "    #converge(\"temp_raw/raw_190625_20X_25K_0001.npy\")\n",
    "    path = \"temp_raw/\"\n",
    "    \n",
    "    #return\n",
    "    with mp.Pool(NUM_CPU) as p:\n",
    "        p.map(converge, [path + filename for filename in os.listdir(path)])\n",
    "    return\n",
    "\n",
    "def converge(path):\n",
    "    try:\n",
    "        loaded_data = np.load(path, allow_pickle=True)\n",
    "        data = np.asarray(loaded_data)\n",
    "        #print(data.shape)\n",
    "\n",
    "        print(data.shape)\n",
    "        print(data[0][0][0].shape)\n",
    "        print(data[1][0][0].shape)\n",
    "\n",
    "        n_patches = 0\n",
    "        for v in range(data.shape[0]):\n",
    "            for z in range(data.shape[1]):\n",
    "                for c in range(data.shape[2]):\n",
    "                    data[v][z][c] = np.asarray(data[v][z][c])\n",
    "\n",
    "        patch_sizes = []\n",
    "        for v in range(data.shape[0]):\n",
    "            n_patches += data[v][0][0].shape[0]\n",
    "            #print(data[v][0].shape[0])\n",
    "            patch_sizes.append(data[v][0][0].shape[0])\n",
    "\n",
    "        print(str(n_patches) + \" patches found\")\n",
    "\n",
    "\n",
    "        y = x = data[0][0][0].shape[1]; c = 4\n",
    "        formatted = np.ndarray(shape=(n_patches, 3, c, y, x))\n",
    "\n",
    "        p_offset = 0\n",
    "        for v in range(data.shape[0]):\n",
    "            n_patches = int(patch_sizes[v])\n",
    "            #print(n_patches)\n",
    "            offset = 0\n",
    "            for p_idx in range(n_patches):\n",
    "                channels = []\n",
    "                for z in range(3):\n",
    "                    for c in range(4):\n",
    "                        formatted[p_offset+offset][z][c] = data[v][z][c][p_idx]\n",
    "                        #print(str(p_offset+offset) + \" \" + str(c))\n",
    "                        #print(str(v) + \" \" + str(c) + \" \" + str(p_idx))\n",
    "                offset+=1\n",
    "            p_offset += n_patches\n",
    "\n",
    "        file = 'patches/raw_3z_20X/raw_'+re.search(\"\\d*_\\d*X_\\d*._\\d*\", path).group(0)+'.npy'\n",
    "        np.save(file, formatted)\n",
    "        print(formatted.shape)\n",
    "        print(\"saved at \" + file)\n",
    "    except:\n",
    "        print(\"invalid file\")\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load(\"patches/raw_20X_50K/data_190627_20X_50K_0001.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "#path = \"patches/raw_20X_50K/data_190627_20X_50K_0001.npy\"\n",
    "NUM_CPU = mp.cpu_count()-1\n",
    "\n",
    "def main():\n",
    "    path = \"patches/raw_40X/\"\n",
    "    with mp.Pool(NUM_CPU) as p:\n",
    "        p.map(converge, [path + filename for filename in os.listdir(path)])\n",
    "    \n",
    "    #for filename in os.listdir(path): # original nd2 filenames\n",
    "    #    converge(path + filename)\n",
    "\n",
    "def converge(path):\n",
    "    loaded_data = np.load(path, allow_pickle=True)\n",
    "    data = np.asarray(loaded_data)\n",
    "    #print(data.shape)\n",
    "\n",
    "    n_patches = 0\n",
    "    for v in range(data.shape[0]):\n",
    "        for c in range(data.shape[1]):\n",
    "            data[v][c] = np.asarray(data[v][c])\n",
    "\n",
    "    patch_sizes = []\n",
    "    for v in range(data.shape[0]):\n",
    "        n_patches += data[v][0].shape[0]\n",
    "        #print(data[v][0].shape[0])\n",
    "        patch_sizes.append(data[v][0].shape[0])\n",
    "\n",
    "    print(str(n_patches) + \" patches found\")\n",
    "\n",
    "    y = x = data[0][0].shape[1]; c = 4\n",
    "    formatted = np.ndarray(shape=(n_patches, c, y, x))\n",
    "\n",
    "    p_offset = 0\n",
    "    for v in range(data.shape[0]):\n",
    "        n_patches = int(patch_sizes[v])\n",
    "        #print(n_patches)\n",
    "        offset = 0\n",
    "        for p_idx in range(n_patches):\n",
    "            channels = []\n",
    "            for c in range(4):\n",
    "                formatted[p_offset+offset][c] = data[v][c][p_idx]\n",
    "                #print(str(p_offset+offset) + \" \" + str(c))\n",
    "                #print(str(v) + \" \" + str(c) + \" \" + str(p_idx))\n",
    "            offset+=1\n",
    "        p_offset += n_patches\n",
    "\n",
    "    file = 'data_'+re.search(\"\\d*_\\d*X_\\d*._\\d*\", path).group(0)+'.npy'\n",
    "    np.save(file, formatted)\n",
    "    print(\"saved at \" + file)\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
